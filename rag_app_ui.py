import streamlit as st
import torch
import re
import pytesseract
import gc
import hashlib
from concurrent.futures import ThreadPoolExecutor
from pdf2image import convert_from_bytes
from setup_models import setup_llm_and_embeddings
from langchain_community.vectorstores import FAISS
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter

from pathlib import Path
import datetime
import json

# ==========================
# Ù…Ø³ÛŒØ±Ù‡Ø§ Ùˆ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
# ==========================
DATA_DIR = Path("data")
OCR_DIR = DATA_DIR / "ocr_texts"
METADATA_DIR = DATA_DIR / "metadata"

OCR_DIR.mkdir(parents=True, exist_ok=True)
METADATA_DIR.mkdir(parents=True, exist_ok=True)

st.set_page_config(
    page_title="Ø³Ø§Ù…Ø§Ù†Ù‡ Ù…Ø±Ú©Ø²ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø³Ù†Ø§Ø¯",
    layout="wide",
    page_icon="ğŸ¢"
)

# ==========================
# session state Ù‡Ø§
# ==========================
if "messages" not in st.session_state:
    st.session_state.messages = []

if "retriever" not in st.session_state:
    st.session_state.retriever = None

if "full_raw_text" not in st.session_state:
    st.session_state.full_raw_text = []

if "metadata_text" not in st.session_state:
    st.session_state.metadata_text = []

if "processed_hashes" not in st.session_state:
    st.session_state.processed_hashes = set()

# ==========================
# Ù…Ø¯Ù„â€ŒÙ‡Ø§
# ==========================
embeddings, llm_engine, prompt_template = setup_llm_and_embeddings()

# ==========================
# ğŸ”‘ ØªØ§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯: Ø¯Ø±ÛŒØ§ÙØª Â«Ú©Ù„ Ù…ØªÙ†Â» Ø¨Ø¯ÙˆÙ† LLM Ùˆ RAG
# ==========================
def get_full_documents_text():
    texts = []
    for metadata_file in METADATA_DIR.glob("*.json"):
        with open(metadata_file, "r", encoding="utf-8") as f:
            metadata = json.load(f)

        ocr_path = Path(metadata["ocr_text_path"])
        if ocr_path.exists():
            with open(ocr_path, "r", encoding="utf-8") as f:
                text = f.read()
            texts.append(
                f"--- {metadata['original_filename']} ---\n{text}"
            )

    return "\n\n".join(texts)

# ==========================
# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø³Ù†Ø§Ø¯ Ù‚Ø¨Ù„ÛŒ
# ==========================
def load_existing_documents(_embeddings):
    all_docs = []
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)

    st.session_state.full_raw_text = []
    st.session_state.metadata_text = []

    for metadata_file in METADATA_DIR.glob("*.json"):
        with open(metadata_file, "r", encoding="utf-8") as f:
            metadata = json.load(f)

        if "book_metadata_text" in metadata:
            st.session_state.metadata_text.extend(metadata["book_metadata_text"])

        ocr_path = Path(metadata["ocr_text_path"])
        if not ocr_path.exists():
            continue

        with open(ocr_path, "r", encoding="utf-8") as f:
            text = f.read()

        st.session_state.full_raw_text.append(
            f"--- {metadata['original_filename']} ---\n{text}"
        )

        for i, chunk in enumerate(splitter.split_text(text)):
            all_docs.append(
                Document(
                    page_content=chunk,
                    metadata={
                        "filename": metadata["original_filename"],
                        "chunk_id": i
                    }
                )
            )

    if all_docs:
        vs = FAISS.from_documents(all_docs, _embeddings)
        return vs.as_retriever(search_kwargs={"k": 8})

    return None


if st.session_state.retriever is None:
    st.session_state.retriever = load_existing_documents(embeddings)

# ==========================
# OCR utils
# ==========================
def clean_text(text):
    text = text.replace("ÛŒ", "ÛŒ").replace("Ú©", "Ú©")
    text = re.sub(r'[^\u0600-\u06FF\s\d.,;?!()\-]', ' ', text)
    return " ".join(text.split())

def process_single_page(args):
    idx, image = args
    raw = pytesseract.image_to_string(image, lang="fas")
    return idx + 1, clean_text(raw)

# ==========================
# OCR + Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ù…Ù†
# ==========================
def process_high_quality_v2(uploaded_files, _embeddings):
    all_docs = []
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    st.session_state.full_raw_text = []

    META_HINTS = ["Ø´Ø§Ø¨Ú©", "ISBN", "Ø§Ù†ØªØ´Ø§Ø±Ø§Øª", "Ù†Ø§Ø´Ø±", "Ú†Ø§Ù¾", "Ù‚ÛŒÙ…Øª", "Ø±ÛŒØ§Ù„", "ØªÙˆÙ…Ø§Ù†"]

    for uploaded_file in uploaded_files:
        original_name = uploaded_file.name
        today = datetime.date.today().strftime("%Y%m%d")

        file_bytes = uploaded_file.read()
        file_hash = hashlib.sha256(file_bytes).hexdigest()[:16]
        uploaded_file.seek(0)

        if file_hash in st.session_state.processed_hashes:
            st.info("Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø± Ø§ÛŒÙ† Ù†Ø´Ø³Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ø§Ø³Øª.")
            continue

        st.session_state.processed_hashes.add(file_hash)

        base_filename = f"{file_hash}_{original_name.replace(' ', '')}"
        ocr_path = OCR_DIR / f"{base_filename}.txt"
        metadata_path = METADATA_DIR / f"{base_filename}.json"
        lock_path = METADATA_DIR / f"{base_filename}.lock"

        if lock_path.exists():
            st.warning("â³ Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ø¯ÛŒÚ¯Ø±ÛŒ Ø§Ø³Øª.")
            continue

        if metadata_path.exists() and ocr_path.exists():
            st.info(f"ÙØ§ÛŒÙ„ {original_name} Ù‚Ø¨Ù„Ø§Ù‹ OCR Ø´Ø¯Ù‡ Ø§Ø³Øª.")
            continue

        lock_path.touch()

        try:
            with st.spinner(f"Ø¯Ø± Ø­Ø§Ù„ OCR: {original_name}"):
                images = convert_from_bytes(uploaded_file.read(), dpi=200)
                pages = []

                with ThreadPoolExecutor(max_workers=4) as ex:
                    results = list(ex.map(process_single_page, enumerate(images)))

                results.sort(key=lambda x: x[0])
                meta_texts = []

                for page_num, page_text in results:
                    pages.append(page_text)
                    all_docs.append(
                        Document(
                            page_content=page_text,
                            metadata={"filename": original_name, "page": page_num}
                        )
                    )
                    if any(k in page_text for k in META_HINTS):
                        meta_texts.append(page_text)

                with open(ocr_path, "w", encoding="utf-8") as f:
                    f.write("\n\n".join(pages))

                metadata = {
                    "original_filename": original_name,
                    "ocr_text_path": str(ocr_path),
                    "upload_date": today,
                    "num_pages": len(pages),
                    "book_metadata_text": meta_texts
                }

                with open(metadata_path, "w", encoding="utf-8") as f:
                    json.dump(metadata, f, ensure_ascii=False, indent=2)

                st.session_state.metadata_text.extend(meta_texts)

        finally:
            if lock_path.exists():
                lock_path.unlink()
            gc.collect()

    if all_docs:
        vs = FAISS.from_documents(all_docs, _embeddings)
        return vs.as_retriever(search_kwargs={"k": 8})

    return None

# ==========================
# UI
# ==========================
st.title("ğŸ¢ Ø³Ø§Ù…Ø§Ù†Ù‡ Ù…Ø±Ú©Ø²ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ù†Ø´ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø§Ø³Ù†Ø§Ø¯")
st.caption("Ù†Ø³Ø®Ù‡ Ù¾Ø§ÛŒØ¯Ø§Ø± Ú†Ù†Ø¯Ú©Ø§Ø±Ø¨Ø±Ù‡")

with st.sidebar:
    uploaded_files = st.file_uploader(
        "ÙØ§ÛŒÙ„ PDF Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯",
        type="pdf",
        accept_multiple_files=True
    )

    if uploaded_files and st.button("Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„"):
        process_high_quality_v2(uploaded_files, embeddings)
        st.session_state.retriever = load_existing_documents(embeddings)
        st.success("Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
        st.rerun()

# ==========================
# Chat
# ==========================
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

if prompt := st.chat_input("Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù¾Ø±Ø³ÛŒØ¯..."):
    if not st.session_state.retriever:
        st.warning("Ù‡ÛŒÚ† Ø³Ù†Ø¯ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
    else:
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            placeholder = st.empty()

            # ğŸ”‘ Ø´Ø±Ø· Ø¬Ø¯ÛŒØ¯: Ø¯Ø±Ø®ÙˆØ§Ø³Øª Â«Ú©Ù„ Ù…ØªÙ†Â»
            if any(x in prompt for x in ["Ú©Ù„ Ù…ØªÙ†", "ØªÙ…Ø§Ù… Ù…ØªÙ†", "Ù…ØªÙ† Ú©Ø§Ù…Ù„"]):
                full_text = get_full_documents_text()
                if not full_text.strip():
                    placeholder.markdown("â„¹ï¸ Ù‡Ù†ÙˆØ² Ù…ØªÙ†ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
                else:
                    placeholder.markdown("### ğŸ“„ Ù…ØªÙ† Ú©Ø§Ù…Ù„ Ø§Ø³Ù†Ø§Ø¯:\n\n" + full_text)

                st.session_state.messages.append({
                    "role": "assistant",
                    "content": full_text
                })
                st.stop()  

            full_res = ""
            is_meta = any(k in prompt for k in ["Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡", "Ù†Ø§Ø´Ø±", "Ù‚ÛŒÙ…Øª", "Ø´Ø§Ø¨Ú©", "ISBN"])

            if is_meta and st.session_state.metadata_text:
                context = "\n\n".join(st.session_state.metadata_text)
            else:
                docs = st.session_state.retriever.invoke(prompt)
                context = "\n\n".join(d.page_content for d in docs)

            context = context[:6000]

            try:
                chain = (
                    {"context": lambda _: context, "question": RunnablePassthrough()}
                    | prompt_template
                    | llm_engine
                    | StrOutputParser()
                )
                for chunk in chain.stream(prompt):
                    full_res += chunk
                    placeholder.markdown(full_res + "â–Œ")
            except Exception:
                full_res = "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ø§Ø³Ø®."

            placeholder.markdown(full_res)
            st.session_state.messages.append({"role": "assistant", "content": full_res})

if torch.cuda.is_available():
    torch.cuda.empty_cache()